{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!python3 -m  pip install  happybase\n",
    "!python3 -m pip install plotly\n",
    "!python3 -m pip install shap\n",
    "!python3 -m pip install \"notebook>=5.3\" \"ipywidgets>=7.2\"\n",
    "!python3 -m pip install catboost\n",
    "!python3 -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns;sns.set()\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from pandas import read_csv, set_option\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer,RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from xgboost import plot_importance,XGBClassifier,XGBRegressor\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime \n",
    "import shap\n",
    "import happybase as hb\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "        \n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# time series cross validation\n",
    "# https://hub.packtpub.com/cross-validation-strategies-for-time-series-forecasting-tutorial/\n",
    "\n",
    "''' FUNCTIONS '''\n",
    "\n",
    "# One plot type\n",
    "def plot_line(ldf,lst,title='',sec_id=None,size=[350,1000]):\n",
    "    \n",
    "    # sec_id - list of [False,False,True] values of when to activate supblots; same length as lst\n",
    "    \n",
    "    if(sec_id is not None):\n",
    "        fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    else:\n",
    "        fig = go.Figure()\n",
    "        \n",
    "    if(len(lst) is not 1):\n",
    "        ii=-1\n",
    "        for i in lst:\n",
    "            ii+=1\n",
    "            if(sec_id is not None):\n",
    "                fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[ii]],mode='lines',name=lst[ii],line=dict(width=2.0)),secondary_y=sec_id[ii])\n",
    "            else:\n",
    "                fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[ii]],mode='lines',name=lst[ii],line=dict(width=2.0)))\n",
    "    else:\n",
    "        fig.add_trace(go.Scatter(x=ldf.index, y=ldf[lst[0]],mode='lines',name=lst[0],line=dict(width=2.0)))\n",
    "\n",
    "    fig.update_layout(height=size[0],width=size[1],template='plotly_white',title=title,\n",
    "                          margin=dict(l=50,r=80,t=50,b=40));fig.show()\n",
    "    \n",
    "# plot n verticle subplots\n",
    "def plot_vsubplots(ldf,lst,title='',nplots=None,lw_id=None,size=[400,1000]):\n",
    "\n",
    "    # lw_id list of line widths if added\n",
    "        \n",
    "    assert(nplots is not None) \n",
    "    fig = make_subplots(rows=nplots,shared_xaxes=True)\n",
    "    ii=-1\n",
    "    for i in lst:\n",
    "        ii+=1\n",
    "        fig.add_trace(go.Scatter(x=ldf.index,y=ldf[lst[ii]], mode='lines',name=lst[ii],line=dict(width=lw_id[ii])), row=ii+1, col=1) \n",
    "\n",
    "    fig.update_layout(height=size[0],width=size[1],template='plotly_white',title=title,\n",
    "                          margin=dict(l=50,r=80,t=50,b=40));fig.show()\n",
    "    \n",
    "colours = ['tab:blue','tab:red','tab:green']\n",
    "def plot_line2(ldf,lst,title=''):\n",
    "    \n",
    "    ii=-1\n",
    "    plt.figure(figsize=(14,5))\n",
    "    for i in lst:\n",
    "        ii+=1\n",
    "        ax = ldf[lst[ii]].plot(color=colours[ii],label=lst[ii],lw=1.5)\n",
    "    plt.title(title)\n",
    "    plt.legend();plt.show()\n",
    "    \n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Plot Correlation to Target Variable only\n",
    "def corrMat(df,target='demand',figsize=(9,0.5),ret_id=False):\n",
    "    \n",
    "    corr_mat = df.corr().round(2);shape = corr_mat.shape[0]\n",
    "    corr_mat = corr_mat.transpose()\n",
    "    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n",
    "    \n",
    "    if(ret_id is False):\n",
    "        f, ax = plt.subplots(figsize=figsize)\n",
    "        sns.heatmap(corr,vmin=-0.3,vmax=0.3,center=0, \n",
    "                     cmap=cmap,square=False,lw=2,annot=True,cbar=False)\n",
    "        plt.title(f'Feature Correlation to {target}')\n",
    "    \n",
    "    if(ret_id):\n",
    "        return corr\n",
    "    \n",
    "def bar_plot(x, y,palette_len,title='Missing Values (%)', xlim = None, ylim = None, \n",
    "             xticklabels = None, yticklabels = None,xlabel = None, ylabel = None, \n",
    "             figsize = (10,4),axis_grid = 'y'):\n",
    "        \n",
    "    cmap = sns.color_palette(\"plasma\")\n",
    "    fig, ax = plt.subplots(figsize = figsize)\n",
    "    plt.title(title,size = 15, fontweight = 'bold')\n",
    "\n",
    "    for i in ['top', 'right', 'bottom', 'left']:\n",
    "        ax.spines[i].set_color('black')\n",
    "    \n",
    "    ax.spines['top'].set_visible(True);ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n",
    "\n",
    "    sns.barplot(x = x, y = y, edgecolor = 'black', ax = ax,\n",
    "                palette = cmap)\n",
    "    ax.set_xlim(xlim);ax.set_ylim(ylim)    \n",
    "    ax.set_xticklabels(xticklabels);ax.set_yticklabels(yticklabels)\n",
    "    plt.xlabel(xlabel);plt.ylabel(ylabel)\n",
    "    ax.grid(axis = axis_grid,ls='--',alpha = 0.9)\n",
    "    plt.show()\n",
    "\n",
    "# function to plot a two PCA Feature Plot using Pandas \n",
    "def scatterPlot(xDF, yDF, algoName):\n",
    "    \n",
    "    sns.set_style('whitegrid')\n",
    "    fig, ax = plt.subplots()\n",
    "    tempDF = pd.DataFrame(data=xDF.loc[:,0:1], index=xDF.index)\n",
    "    tempDF = pd.concat((tempDF,yDF), axis=1, join=\"inner\")\n",
    "    tempDF.columns = [\"Component 1\",\"Component 2\",\"Label\"]\n",
    "    g = sns.scatterplot(x=\"Component 1\",y=\"Component 2\",data=tempDF,hue=\"Label\",\n",
    "                        linewidth=0.5,alpha=0.5,s=15,edgecolor='k')\n",
    "    plt.title(algoName);plt.legend()\n",
    "    \n",
    "    for i in ['top', 'right', 'bottom', 'left']:\n",
    "        ax.spines[i].set_color('black')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False);ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False);ax.spines['left'].set_visible(False)\n",
    "    ax.grid(axis = 'both',ls='--',alpha = 0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# reduce memory (@mfjwr1); distorts the data a little (but reduces by 60% memory)\n",
    "def red_mem(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "# Split for TimeSeries\n",
    "def TimeSeries_Split(ldf,\n",
    "                     split_id=[None,None],\n",
    "                     test_id=False,\n",
    "                     cut_id=None):\n",
    "    \n",
    "    # Reduce the number of used data\n",
    "    if(cut_id is not None):\n",
    "        print('Reducing Input Data')\n",
    "        \n",
    "        if(type(cut_id) is int):\n",
    "            ldf = ldf.iloc[-cut_id:]\n",
    "        else:\n",
    "            # input anything other than int\n",
    "            print('Slicing based on period')\n",
    "            ldf = ldf[data_period]\n",
    "            \n",
    "        t1 = ldf.index.max();t0 = ldf.index.min()\n",
    "        print(f'Dataset Min.Index: {t0} | Max.Index: {t1}')\n",
    "        \n",
    "    if(split_id[0] is not None):\n",
    "        # General Percentage Split (Non Shuffle requied for Time Series)\n",
    "        train_df,pred_df = train_test_split(ldf,test_size=split_id[0],shuffle=False)\n",
    "    elif(split_id[1] is not None):\n",
    "        # specific time split \n",
    "        train_df = df.loc[:split_id[1]]; pred_df = df.loc[split_id[1]:] \n",
    "    else:\n",
    "        print('Choose One Splitting Method Only')\n",
    "        \n",
    "#     y_train = train_df[feature]\n",
    "#     X_train = train_df.loc[:, train_df.columns != feature]\n",
    "#     if(test_id):\n",
    "#         y_test = pred_df[feature]\n",
    "#         X_test = pred_df.loc[:, pred_df.columns != feature]\n",
    "        \n",
    "    return train_df,pred_df # return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  load_data_from_hbase(con:hb.Connection,tablename:str,row_start:str, row_stop):\n",
    "    con.open()\n",
    "    table = con.table(tablename)\n",
    "    print(con.tables())\n",
    "    candlesticks= [ data for key,data in table.scan(row_start=row_start.encode(\"utf-8\"), row_stop=row_stop.encode(\"utf-8\"))]\n",
    "    df = pd.DataFrame(candlesticks).apply(lambda  x: x.apply(lambda  y:  float(y.decode(\"utf-8\").replace('\\'',''))))\n",
    "    columns  = [c.decode(\"utf-8\") for c in df.columns]\n",
    "    df.columns =  columns\n",
    "    df.rename(columns={\"CANDLESTICKES:close\": \"Close\", \"CANDLESTICKES:open\":\"Open\",\"CANDLESTICKES:high\":\"High\",\"CANDLESTICKES:low\":\"Low\",\"CANDLESTICKES:volume\":\"Volume_(Currency)\", \"CANDLESTICKES:close_time\":\"Timestamp\"}, inplace=True)\n",
    "    df['Timestamp'] = df['Timestamp'].apply(lambda x : int(x)//1000)\n",
    "    df['date'] = df['Timestamp'].apply(lambda  x : datetime.fromtimestamp(x))\n",
    "    df.set_index('date', inplace=True)\n",
    "    con.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>PROBLEM DEFINITION</span></b></p></div>\n",
    "\n",
    "- A major drawback of crypocurrency trading is the **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">volatility</mark>** of the market.\n",
    "- The currency trades can occur 24/7 & tracking crypto position can be an impossible task to manage without automation.\n",
    "- Automated Machine Learning trading algorithms can assist in managing this task, in order to predict the market's movement.\n",
    "- We can use models to classify future movements into three categries: \n",
    "\n",
    "> <code>(1) The market will rise (take long position)</code>, <br>\n",
    "> <code>(2) The market will fall (take short position)</code> <br>\n",
    "> <code>(3) The market will move sideways (take no position)</code>.\n",
    "    \n",
    "    \n",
    "- The problem of predicting a buy (<code>value=1</code>) or sell (<code>value=0</code>) signal for a **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">trading strategy</mark>** is defined in the\n",
    "classification framework. \n",
    "- The buy or sell signal are decided on the basis of a comparison of short term vs. long\n",
    "term price & is defined in <code>Section 2.2</code>\n",
    "- Data harvesting (just data collection here) & <code>feature engineering</code> are relevant factors in time series model improvement. \n",
    "- It's interesting to investigate whether traditionally stock orientated feature engineering modifications are relevant to <code>digital assets</code>, and if so which ones\n",
    "- Last but not least, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">model generation efficiency</mark>** becomes much more significant when dealing with **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">High Frequency Tick Data</mark>** as each added feature can have a substatial impact on the turnaround time of a model, due to the amount of data & balancing model accuracy & model output turnaround time is definitely worth managing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>DEFINITION DU PROBLEME</span></b></p></div>\n",
    "\n",
    "- Un inconvénient majeur du trading de cryptomonnaies est la **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">volatilité</mark>** du marché.\n",
    "- Les échanges de devises peuvent avoir lieu 24h/24 et 7j/7 et le suivi de la position cryptographique peut être une tâche impossible à gérer sans automatisation.\n",
    "- Les algorithmes de trading automatisés de Machine Learning peuvent aider à gérer cette tâche, afin de prédire le mouvement du marché.\n",
    "- Nous pouvons utiliser des modèles pour classer les mouvements futurs en trois catégories : \n",
    "\n",
    "> <code>(1) Le marché va augmenter (prendre une position longue), <br>\n",
    "> <code>(2) Le marché va baisser (prendre une position courte)</code> <br>\n",
    "> <code>(3) Le marché évoluera latéralement (ne prendra pas de position).</code>.\n",
    "    \n",
    "- Le problème de la prédiction d'un signal d'achat (<code>valeur = 1</code>) ou de vente (<code>valeur = 0</code>) pour une **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">stratégie de trading</mark>** est défini dans le cadre de classification.\n",
    "- Le signal d'achat ou de vente est décidé sur la base d'une comparaison des prix à court terme vs à long terme est défini dans la <code>section 2.2</code>.\n",
    "-  La collecte de données (uniquement la collecte de données ici) et <code>l'ingénierie des fonctionnalités</code> sont des facteurs pertinents dans l'amélioration des modèles de séries chronologiques.\n",
    "-  Il est intéressant de déterminer si les modifications d'ingénierie de fonctionnalités traditionnellement orientées sur les stocks sont pertinentes pour <code>les actifs numériques</code>, et si oui, lesquelles.\n",
    "-  Enfin et surtout, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">l'efficacité de la génération de modèles</mark>** devient beaucoup plus significative lorsqu'il s'agit de **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">données de ticks à haute fréquence</mark>**, car chaque fonctionnalité ajoutée peut avoir un impact substatiel sur le délai d'exécution d'un modèle, en raison de la quantité de données et de l'équilibrage de la précision du modèle et du délai de production du modèle. le temps vaut vraiment la peine d'être géré"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#CDE10F\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>LE JEU DE DONNÉES</b></div>\n",
    "\n",
    "<div style=“color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;”><p style=“padding: 5px;color:white;text-align:left;”><b><span style=‘color:#CDE10F’>LECTURE DU JEU DE DONNÉES</span></b></p></div>\n",
    "\n",
    "- Jeu de données actuel : Une extraction de chandeliers financières du bitcoin, la periode choisi est de octobre 2022 à octobre 2023 <code>à intervalle de 15 minutes<code>\n",
    "- La caractéristique <code>timestamp</code> peut être analysée en un index de temps plus conventionnel en utilisant la bibliothèque <code>pytz</code>.\n",
    "- Les <code>Caractéristiques de base</code> comprennent : <code>Open</code>, <code>High</code>, <code>Low</code>, <code>Close</code>, <code>Volume_(Currency)</code> de l’actif au quart d'heure\n",
    "- Le jeu de données chargé contient un index de temps de début et de fin spécifiques, afin d’utiliser des modèles sur des données non vues, nous devons diviser le jeu de données et ne pas l’inspecter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = hb.Connection('hbase',9090)\n",
    "df = load_data_from_hbase(con,\"BINANCE\",'BTCUSDT-15m#20221001', 'BTCUSDT-15m#20231001')\n",
    "display(df.head(5))\n",
    "display(df.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, pytz\n",
    "#define a conversion function for the native timestamps in the csv file\n",
    "def dateparse (time_in_secs):    \n",
    "    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))\n",
    "\n",
    "# Data Periods used in Notebook\n",
    "plot_period = slice('2023-01-19 14:59','2023-01-25 23:59') # Selectio Plot Period for visualisation only\n",
    "data_period = slice('2022-10-01 14:59','2023-09-30 23:59') # Select Data Period for Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>TRAVAILLER AVEC UN SOUS-ENSEMBLE DE DONNÉES</span></b></p></div>\n",
    "\n",
    "- En raison de l’excès de données d’index disponibles pour nous, la formation des modèles peut devenir assez longue, surtout lorsqu’il s’agit de validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr,df_te = TimeSeries_Split(df,split_id=[0.2,None], #  Train/Test Split (0.8/0.2)\n",
    "                               cut_id=data_period)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#CDE10F\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>EXPLORER LES  DONNEES</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>STATISTIQUE DESCRIPTIVE</span></b></p></div>\n",
    "\n",
    "Étudions les statistiques des valeurs numériques de l'ensemble de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_option('precision',2)\n",
    "df_tr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>VARIABLE CIBLE</span></b></p></div>\n",
    "\n",
    "- Nous devons définir notre variable de prédiction <code>signal</code>, qui sera réalisée via <code>.rolling</code> & <code>.mean()</code> en utilisant la caractéristique <code>Close</code>.\n",
    "- Une moyenne mobile à court terme (fenêtre), <code>SMA1</code> & une moyenne mobile à long terme (fenêtre), <code>SMA2</code> sont utilisées pour créer la variable cible, <code>signal</code>.\n",
    "- La stratégie de trading est la suivante ; lorsque le <code>Short Term (SMA1)</code> > <code>Long Term (SMA2)</code>, la valeur du signal = 1 <code>(achat)</code>, sinon elle est fixée à 0 <code>(vente)</code>.\n",
    "- La valeur de la moyenne mobile à <code>Short Term (SMA1)</code> & <code>Long Term (SMA2)</code> sont fixées à des <b>valeurs de fenêtre de 10 et 60</b> respectivement, toutes deux sont arbitraires, et peuvent affecter les résultats, idéalement une étude d’optimisation doit être réalisée pour trouver les valeurs optimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(ldf,tr_id=False):\n",
    "    ldf['SMA1'] = ldf['Close'].rolling(window=10, min_periods=1, center=False).mean() #  short simple moving average window\n",
    "    ldf['SMA2'] = ldf['Close'].rolling(window=60, min_periods=1, center=False).mean() #  long simple moving average window\n",
    "    ldf['signal'] = np.where(ldf['SMA1'] > ldf['SMA2'], 1.0, 0.0) # Create signals\n",
    "    if(tr_id is not True):\n",
    "        display(ldf['signal'].value_counts())\n",
    "    \n",
    "df_tr1 = df_tr.copy()  # Save the Baseline Model Dataframe [Training Set]\n",
    "df_te1 = df_te.copy() # Save the Baseline Model Dataframe [Test Set]\n",
    "create_target(df_tr1)  # Add target variable to Training Set \n",
    "create_target(df_te1,tr_id=True)  # Add target variable to Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous avons une distribution de <code>signal</code> de variable cible relativement uniforme (achat/vente) (13.8k/14.1k)\n",
    "- Nous n'avons pas vraiment besoin de souligner les problèmes associés au <code>déséquilibre des classes</code> dans ce problème\n",
    "- Des métriques simples telles que <code>accuracy,recall,precision</code> pourraient suffire comme métriques de <code>classification</code>, au lieu des courbes ROC et PR détaillées des modèles de classificateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>VISUALISATION DE SÉRIES TEMPORELLES DE JEUX DE DONNÉES</span></b></p></div>\n",
    "\n",
    "Let's visualise the overall asset price history during the <code>training data</code> period & the associated <code>signal</code> as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vsubplots(df_tr1,['Close','signal'],\n",
    "               title='Prix de cloture & signal des données d\\'entrainement',\n",
    "               nplots=2,\n",
    "               lw_id=[2,0.4],\n",
    "               size=[500,1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il est intéressant de noter la tendance générale à la hausse du prix <code>de cloture</code> des actifs, passant de 20k au début de cette période à 30k seulement en l'espace de quelques mois.\n",
    "- Pas tout à fait facile à visualiser, le signal (ce que nous allons modéliser) est également tracé, et nous pouvons observer à quel point les MA de période plus courte et plus longue s'échangent au cours de cette seule courte période de temps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise Training Set Target Variable Related Features\n",
    "\n",
    "lst_MAV = ['SMA1','SMA2','signal']\n",
    "ldf = df_tr1.loc[plot_period,lst_MAV]\n",
    "plot_line(ldf,lst_MAV,\n",
    "          title='SM1, SMA2 & Signal created from Closing Price',\n",
    "          sec_id=[False,False,True])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir qu'il existe un certain nombre de périodes pendant lesquelles les valeurs de moyenne mobile les plus courtes et les plus longues s'échangent, même pour une période de <b>48 heures</b> seulement, au cours de laquelle le coût variait dans la plage de <code>21k:23k</code> au cours de la période observée, ce qui indique un actif très volatil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr1=df_tr1.drop(['SMA1','SMA2','Timestamp'], axis=1)\n",
    "df_te1=df_te1.drop(['SMA1','SMA2','Timestamp'], axis=1)   # replicate on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#CDE10F'> 3.1 |</span> Caractéristiques du modèle de base</b>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>CORRÉLATION DES CARACTÉRISTIQUES DE BASE</span></b></p></div>\n",
    "\n",
    "Définissons le terme de \"base\" ; les caractéristiques qui sont disponibles pour être utilisées dans le jeu de données, c’est-à-dire open, close, etc.\n",
    "\n",
    "Les valeurs de corrélation linéaire de nos caractéristiques actuelles <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code>,<code>volumes</code> avec la variable cible sont très minimes.\n",
    "Elles ne sont pas les plus idéales pour modéliser la cible, <code>signal</code>, et peuvent être améliorées, donc l’attention se déplace vers <code>le  feature engineering</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(df_tr1,'signal',figsize=(7,0.5)) # Baseline Dataframe feature correlation to Signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>INGÉNIERIE DES CARACTÉRISTIQUES</span></b></p></div>\n",
    "\n",
    "-  Comme indiqué dans l’introduction, dans le problème actuel, nous nous concentrerons sur les <code>indicateurs techniques</code> dans le cadre de notre approche de<code>feature engineering</code> dans le but d’introduire des caractéristiques plus pertinentes dans la <code>matrice des caractéristiques</code>.\n",
    "- Il est intéressant de savoir (dans le contexte d’un <code>actif numérique</code>), quelles caractéristiques ont un impact sur les performances du modèle, le cas échéant.\n",
    "  \n",
    "<b>Plus précisément :</b>\n",
    "\n",
    "- <code>Moyenne mobile</code> : Une moyenne mobile donne une indication de la tendance du mouvement des prix en réduisant la quantité de bruit. <br>\n",
    "- <code>Oscillateur stochastique %K et %D</code> : Un oscillateur stochastique est un indicateur de momentum comparant un prix de clôture particulier d’un titre à une gamme de ses prix sur une certaine période de temps. %K et %D sont des indicateurs lents et rapides. <br>\n",
    "- <code>Indice de force relative (RSI)</code> : C’est un indicateur de momentum qui mesure l’ampleur des changements de prix récents pour évaluer les conditions de surachat ou de survente dans le prix d’une action ou d’un autre actif. Allant de [0,100]. <b>Actif -> 70 : actif considéré comme suracheté</b>. <b>Actif -> 30 : actif sous-vendu et sous-évalué.</b><br>\n",
    "- <code>Taux de changement (ROC)</code>: C’est un oscillateur de momentum, qui mesure le pourcentage de changement entre le prix actuel et le prix passé n période. Les actifs avec des <b>valeurs ROC plus élevées</b> sont considérés comme plus susceptibles d’être surachetés et <b>ROC plus bas</b>; plus susceptibles d’être survendus.<br>\n",
    "- <code>Momentum (MOM)</code> : C’est le taux d’accélération du prix ou du volume d’un titre ; la vitesse à laquelle le prix change. <br>\n",
    "Peuvent tous être potentiellement utiles pour modéliser la variable cible, <code>signal</code>, avec bien sûr des degrés d’influence variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr2 = df_tr1.copy()  # Create duplicate dataframe & add features to it\n",
    "df_te2 = df_tr2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Technical Indicators '''\n",
    "\n",
    "#Calculation of moving average\n",
    "def ma(df, n):\n",
    "    return pd.Series(df['Close'].rolling(n, min_periods=n).mean(), name='MA_' + str(n))\n",
    "\n",
    "# exponentially weighted moving average \n",
    "def ema(df, n):\n",
    "    return pd.Series(df['Close'].ewm(span=n,min_periods=n).mean(), name='EMA_' + str(n))\n",
    "\n",
    "#Calculation of price momentum\n",
    "def mom(df, n):     \n",
    "    return pd.Series(df.diff(n), name='Momentum_' + str(n))  \n",
    "\n",
    "# rate of change\n",
    "def roc(df, n):  \n",
    "    M = df.diff(n - 1) ; N = df.shift(n - 1)  \n",
    "    return pd.Series(((M / N) * 100), name = 'ROC_' + str(n)) \n",
    "\n",
    "# relative strength index\n",
    "def rsi(df, period):\n",
    "    delta = df.diff().dropna()\n",
    "    u = delta * 0; d = u.copy()\n",
    "    u[delta > 0] = delta[delta > 0]; d[delta < 0] = -delta[delta < 0]\n",
    "    u[u.index[period-1]] = np.mean( u[:period] ) #first value is sum of avg gains\n",
    "    u = u.drop(u.index[:(period-1)])\n",
    "    d[d.index[period-1]] = np.mean( d[:period] ) #first value is sum of avg losses\n",
    "    d = d.drop(d.index[:(period-1)])\n",
    "    rs = u.ewm(com=period-1, adjust=False).mean() / d.ewm(com=period-1, adjust=False).mean()\n",
    "    return 100 - 100 / (1 + rs)\n",
    "\n",
    "# stochastic oscillators slow & fast\n",
    "def sto(close, low, high, n,id): \n",
    "    stok = ((close - low.rolling(n).min()) / (high.rolling(n).max() - low.rolling(n).min())) * 100\n",
    "    if(id is 0):\n",
    "        return stok\n",
    "    else:\n",
    "        return stok.rolling(3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def tech_indi(ldf,tr_id=True):\n",
    "\n",
    "    ''' Moving Average '''\n",
    "    ldf['MA21'] = ma(ldf,10)\n",
    "    ldf['MA63'] = ma(ldf, 30)\n",
    "    ldf['MA252'] = ma(ldf, 200)\n",
    "    lst_MA = ['MA21','MA63','MA252']\n",
    "\n",
    "    ''' Exponentially Weighted Moving Average '''\n",
    "    ldf['EMA10'] = ema(ldf, 10)\n",
    "    ldf['EMA30'] = ema(ldf, 30)\n",
    "    ldf['EMA200'] = ema(ldf, 200)\n",
    "    lst_EMA = ['EMA10','EMA30','EMA200']\n",
    "\n",
    "    ''' Momentum '''\n",
    "    ldf['MOM10'] = mom(ldf['Close'], 10)\n",
    "    ldf['MOM30'] = mom(ldf['Close'], 30)\n",
    "    lst_MOM = ['MOM10','MOM30']\n",
    "\n",
    "    ''' Relative Strength Index '''\n",
    "    ldf['RSI10'] = rsi(ldf['Close'], 10)\n",
    "    ldf['RSI30'] = rsi(ldf['Close'], 30)\n",
    "    ldf['RSI200'] = rsi(ldf['Close'], 200)\n",
    "    lst_RSI = ['RSI10','RSI30','RSI200']\n",
    "\n",
    "    ''' Slow Stochastic Oscillators '''\n",
    "    ldf['%K10'] = sto(ldf['Close'], ldf['Low'], ldf['High'],5,0)\n",
    "    ldf['%K30'] = sto(ldf['Close'], ldf['Low'], ldf['High'],10,0)\n",
    "    ldf['%K200'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 20,0)\n",
    "    lst_pK = ['%K10','%K30','%K200']\n",
    "\n",
    "    ''' Fast Stochastic Oscillators '''\n",
    "    ldf['%D10'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 10,1)\n",
    "    ldf['%D30'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 30,1)\n",
    "    ldf['%D200'] = sto(ldf['Close'], ldf['Low'], ldf['High'], 200,1)\n",
    "    lst_pD = ['%D10','%D30','%D200']\n",
    "    \n",
    "    # Plot Training Data\n",
    "    if(tr_id):\n",
    "        plot_line(ldf.loc[plot_period,lst_MA],lst_MA,title='Moving Average (window=21,63,252)')\n",
    "        plot_line(ldf.loc[plot_period,lst_EMA],lst_EMA,title='Exponential Moving Average (window=10,30,200)')\n",
    "        plot_line(ldf.loc[plot_period,lst_MOM],lst_MOM,title='Momentum')\n",
    "        plot_line(ldf.loc[plot_period,lst_RSI],lst_RSI,title='Relative Strength Index')\n",
    "        plot_line(ldf.loc[plot_period,lst_pK],lst_pK,title='Stochastic Oscillators (slow)')\n",
    "        plot_line(ldf.loc[plot_period,lst_pD],lst_pD,title='Stochastic Oscillators (Fast)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_indi(df_tr2) # add technical features to training set\n",
    "tech_indi(df_te2,tr_id=False) # add technical features to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the current features\n",
    "df_tr2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#CDE10F'> 3.2 |</span> Mise à jour des caractéristiques (features) du modèle</b> \n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>CORRÉLATION LINÉAIRE DES CARACTERISTIQUES MISE À JOUR</span></b></p></div>\n",
    "\n",
    "- Avoir créé de nouvelles caractéristiques ; <code>MA</code>,<code>EMA</code>,<code>MOM</code>,<code>RSI</code>,<code>%K/%D</code>,\n",
    "- étudions la corrélation linéaire de ces nouvelles caractéristiques avec la variable cible et comparons-les aux caractéristiques de l'<code>ensemble des caractéristiques de base</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMat(df_tr2,'signal',figsize=(15,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous pouvons voir le groupe de caractéristiques significativement plus linéairement corrélées qui ont été créées à la suite du <code>feature engineering</code>.\n",
    "- Il est probable que les caractéristiques de l'ensemble de données <code>base</code> n'auront que peu ou pas d'impact sur la variation de la variable cible si elles sont utilisées dans la <code>matrice de caractéristiques</code>.\n",
    "- D'un autre côté, les caractéristiques nouvellement créées ont une plage de valeurs corrélées raisonnablement large, et assez importante ; ne sont pas trop fortement corrélés à la variable cible, <code>signal</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drp_feat(ldf):\n",
    "    ldf = ldf.drop(['High','Low','Open','Volume_(Currency)'], axis=1) # let's drop most of the original feature\n",
    "    \n",
    "drp_feat(df_tr2)\n",
    "drp_feat(df_te2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir appliqué des fonctions à notre <code>matrice de caractéristiques</code>, nous devons revérifier les données manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_values = (df_tr2.isnull().sum() / len(df_tr2) * 100).sort_values(ascending = False)\n",
    "bar_plot(x = NaN_values,y = NaN_values.index,palette_len = NaN_values.index, \n",
    "         xlim = (0,1),xticklabels = range(0,10),yticklabels = NaN_values.index,\n",
    "         figsize = (10,5), axis_grid = 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tr2 = df_tr2.dropna() \n",
    "df_te2 = df_te2.dropna()\n",
    "df_tr2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow : Hidden;background-color:#CDE10F\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>GÉNÉRATION DE MODÈLES</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text- align:left;\"><b><span style='color:#CDE10F'>FONCTION D'ÉVALUATION</span></b></p></div>\n",
    "\n",
    "\n",
    "Après avoir défini une <code>variable cible</code> et une <code>matrice de caractéristiques</code> claires, passons en revue ce que nous avons : <br><br>\n",
    "- df_tr1/df_te1 : <code>Dataframe d'entraînement/test des caractéristiques de base associées à l'actif</code>\n",
    "- df_tr2/df_te2 : <code>DataFrame de données d'entrainement/test des caractéristiques nouvellement créées lors de l'étape de  feature engineering </code>\n",
    "\n",
    "Et nous pouvons commencer à créer des modèles pour prédire la variable cible <code>signal</code> (directivité du marché), en utilisant la fonction d'évaluation ci-dessous.\n",
    "\n",
    "<b>La fonction d'évaluation est (cachée ci-dessous) :</b><br><br>\n",
    "L'objectif de la fonction d'évaluation est d'évaluer les performances du modèle sur différentes approches de répartition et d'évaluation des données.\n",
    "\n",
    "<b>(1)</b> La fonction prend dans un <code>dataframe</code> qui contient à la fois la <code>matrice de caractéristiques, X</code> et la <code>variable cible, y</code> . <br>\n",
    "<b>(2)</b> Les données sont divisées en deux parties ; <code>train_df</code> & <code>eval_df</code> <br>\n",
    "<b>(3)</b> Une évaluation par <code>cross-validation</code> en 5-Folds de la dataframe de données importée est évaluée pour obtenir une image de la performance du modèle sur les données d'entraînement (petits et gros morceaux )<br>\n",
    "<b>(4)</b> Un partage bidirectionnel standard (sans brassage de données) est effectué et entraîné sur <code>X_train/y_train</code> et <code>X_eval/y_eval</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "# Lightweight Models \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))  # Unsupervised Model \n",
    "models.append(('KNN', KNeighborsClassifier()))  # Unsupervised Model\n",
    "models.append(('TREE', DecisionTreeClassifier())) # Supervised Model\n",
    "models.append(('NB', GaussianNB())) # Unsupervised Model\n",
    "\n",
    "# More Advanced Models\n",
    "models.append(('GBM', GradientBoostingClassifier(n_estimators=25)))\n",
    "models.append(('XGB',XGBClassifier(n_estimators=25,eval_metric='logloss')))\n",
    "models.append(('CAT',CatBoostClassifier(silent=True,\n",
    "                                        n_estimators=25)))\n",
    "models.append(('RF', RandomForestClassifier(n_estimators=25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# eval_id (T/F): [CV,Train,Test,all]\n",
    "\n",
    "def modelEval(ldf,feature='signal',split_id=[None,None],eval_id=[True,True,True,True],\n",
    "              n_fold=5,scoring='accuracy',plot_id=[False,True],cv_yrange=None,hm_vvals=[0.5,1.0,0.75]):\n",
    "    \n",
    "    print('Evaluation Function')\n",
    "    print(f'Cross Validation Activated, n_splits : {n_fold}, scoring metric: {scoring}')\n",
    "    if(eval_id[2]):\n",
    "        if(split_id[0] is not None):\n",
    "            print(f'Train/Evaluation Set Spit Activated: {split_id[0]}')\n",
    "        if(split_id[1] is not None):\n",
    "            print(f'Train/Evaluation Set Split made at {split_id[1]}')\n",
    "    \n",
    "    ''' 1. Split Train/Evaluation <DataFrame> Set Split '''\n",
    "    \n",
    "    # split_id : Train/Test split [%,timestamp], whichever is not None\n",
    "    # test_id : Evaluate trained model on test set only\n",
    "    \n",
    "    if(split_id[0] is not None):\n",
    "        # General Percentage Split (Non Shuffle requied for Time Series)\n",
    "        train_df,eval_df = train_test_split(ldf,test_size=split_id[0],shuffle=False)\n",
    "    elif(split_id[1] is not None):\n",
    "        # specific time split \n",
    "        train_df = df.loc[:split_id[1]]; eval_df = df.loc[split_id[1]:] \n",
    "    else:\n",
    "        print('Choose One Splitting Method Only')\n",
    "        \n",
    "    ''' 2. Train/Test Feature Matrices + Target Variables Split'''\n",
    "    \n",
    "    y_train = train_df[feature]\n",
    "    X_train = train_df.loc[:, train_df.columns != feature]\n",
    "    y_eval = eval_df[feature]\n",
    "    X_eval = eval_df.loc[:, eval_df.columns != feature]\n",
    "    X_one = pd.concat([X_train,X_eval],axis=0)\n",
    "    y_one = pd.concat([y_train,y_eval],axis=0)\n",
    "    \n",
    "    print('');print(f'Using Features: {X_train.columns}')\n",
    "    print(f'Target Variable: {feature}');print('')\n",
    "        \n",
    "    ''' 3. Visualise Training/Test Data'''\n",
    "    if(plot_id[0]):\n",
    "        \n",
    "        # plot the training data\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=train_df.index, y=train_df['signal'],mode='lines',name='Training Data', line={'width': 0.25}))\n",
    "        fig.update_layout(height=300,width=800,template='plotly_white',title='Training Signal Visualisation',\n",
    "                          margin=dict(l=50,r=80,t=50,b=40))\n",
    "        \n",
    "        # Plot the test data as well \n",
    "        if(eval_id[2]):\n",
    "            fig.add_trace(go.Scatter(x=eval_df.index, y=eval_df['signal'],mode='lines',name='Test Data',line={'width': 0.25}))\n",
    "            fig.update_layout(title='Training/Test Signal Visualisation')\n",
    "        fig.show()\n",
    "    \n",
    "    ''' 4. Cross Validation, Training/Evaluation, one evaluation'''\n",
    "    lst_res = []; names = []; lst_train = []; lst_eval = []; lst_one = []; lst_res_mean = []\n",
    "    if(any(eval_id)):\n",
    "        for name, model in models:  # cycle through models & evaluate either cv or train/test\n",
    "            names.append(name)\n",
    "            \n",
    "            # Cross Validation Model on Training Se\n",
    "            if(eval_id[0]):\n",
    "                t0=time.time()\n",
    "                kfold = KFold(n_splits=n_fold)\n",
    "                cv_res = cross_val_score(model,X_train,y_train, cv=kfold, scoring=scoring)\n",
    "                t1 = time.time()\n",
    "                lst_res.append(cv_res)\n",
    "                tt1 = t1-t0 # total time for n_fold cross evaluation\n",
    "                \n",
    "            # Evaluate Fit Model on Training Data\n",
    "            t2 = time.time()\n",
    "            if(eval_id[1]):\n",
    "                t2 = time.time()\n",
    "                res = model.fit(X_train,y_train)\n",
    "                train_res = accuracy_score(res.predict(X_train),y_train); lst_train.append(train_res)\n",
    "            if(eval_id[2]):\n",
    "                if(eval_id[1] is False):  # If training hasn't been called yet\n",
    "                    res = model.fit(X_train,y_train)\n",
    "                eval_res = accuracy_score(res.predict(X_eval),y_eval); lst_eval.append(eval_res)\n",
    "            t3 = time.time()\n",
    "            tt2 = t3-t2 # total time for training/evaluation train/prediction\n",
    "            \n",
    "            # Evaluate model on entire dataset\n",
    "            if(eval_id[3]):\n",
    "                t4 = time.time()\n",
    "                res = model.fit(X_one,y_one)\n",
    "                one_res = accuracy_score(res.predict(X_one),y_one); lst_one.append(one_res)\n",
    "                t5 = time.time()\n",
    "                tt3 = t5-t4 # total time for training & evaluation on whole dataframe\n",
    "            \n",
    "            ''' [out] Verbal Outputs '''\n",
    "            # Cross Validation / Training / Evaluation Model Evaluation / Section Times\n",
    "            lst_res_mean.append(cv_res.mean())\n",
    "            fn1 = cv_res.mean(); fn2 = cv_res.std();\n",
    "            fn3 = train_res; fn4 = eval_res; fn5 = one_res\n",
    "            print(f\"{name} : {fn1:.3f}({fn2:.3f}) -> {tt1:.2f}s | {fn3:.3f} & {fn4:.3f} -> {tt2:.2f}s | {fn5:.3f} -> {tt3:.2}s\")\n",
    "      \n",
    "    s0 = pd.Series(np.array(lst_res_mean),index=names)\n",
    "    s1 = pd.Series(np.array(lst_train),index=names)\n",
    "    s2 = pd.Series(np.array(lst_eval),index=names)\n",
    "    s3 = pd.Series(np.array(lst_one),index=names)\n",
    "    pdf = pd.concat([s0,s1,s2,s3],axis=1)\n",
    "    pdf.columns = ['cv_average','train','test','all']\n",
    "    s4 = pd.Series([tt1,tt2,tt3],index=['cv','train/test','all'])\n",
    "        \n",
    "    ''' 5. Visual Ouputs '''\n",
    "    if(plot_id[1]): \n",
    "        \n",
    "        sns.set(style=\"whitegrid\")\n",
    "        fig,ax = plt.subplots(1,2,figsize=(15,4))\n",
    "        ax[0].set_title(f'{n_fold} Cross Validation Results')\n",
    "        sns.boxplot(data=lst_res, ax=ax[0], orient=\"v\",width=0.3)\n",
    "        ax[0].set_xticklabels(names)\n",
    "        sns.stripplot(data=lst_res,ax=ax[0], orient='v',color=\".3\",linewidth=1)\n",
    "        ax[0].set_xticklabels(names)\n",
    "        ax[0].xaxis.grid(True)\n",
    "        ax[0].set(xlabel=\"\")\n",
    "        if(cv_yrange is not None):\n",
    "            ax[0].set_ylim(cv_yrange)\n",
    "        sns.despine(trim=True, left=True)\n",
    "    \n",
    "        sns.heatmap(pdf,vmin=hm_vvals[0],vmax=hm_vvals[1],center=hm_vvals[2],\n",
    "                    ax=ax[1],square=False,lw=2,annot=True,fmt='.3f',cmap='Blues')\n",
    "        ax[1].set_title('Accuracy Scores')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#CDE10F'> 4.1 |</span> ÉVALUATION DU MODÈLE DE CARACTÉRISTIQUES DE BASE</b>\n",
    "\n",
    "- Les **<span style='color:#CDE10F'>Caractéristiques de base</span>** comprennent :\n",
    "> Les 15 minutes de l’actif <code>open</code>,<code>high</code>,<code>low</code>,<code>close</code> & <code>Volume_(Currency)</code>\n",
    "- Comme je l’ai découvert, dans les applications de séries temporelles, il n’est pas très courant d’utiliser des caractéristiques de base associées à un seul actif, mais voyons comment cela se passe de toute façon, traçons également les données d’entraînement pour avoir une idée visuelle de ce que nous essayons de modéliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmodelEval(df_tr1,split_id=[0.2,None],plot_id=[False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous pouvons voir que le **<span style='color:#CDE10F'>cross_val_score</span>** se situe aux alentours de **<span style='color:#CDE10F'>précision = 0.5</span>**, ce qui suggère que l’utilisation de **<span style='color:#CDE10F'>caractéristiques de base</span>** associées à un seul actif n’est pas tout à fait adaptée pour prédire avec précision la **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">directivité de l’actif</mark>**\n",
    "\n",
    "- La plupart des modèles avaient tendance à avoir un **<span style='color:#CDE10F'>score d’entraînement</span>** plus élevé que le **<span style='color:#CDE10F'>score de validation croisée</span>**\n",
    "\n",
    "- Il était intéressant de voir que le **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">DecisionTreeClassifier</mark>** & **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">RandomForest</mark>**, même avec très peu d’estimateurs sont capables d’atteindre des scores très élevés (même s’ils sont en sur-apprentissage)\n",
    "\n",
    "- Cela suggère que les modèles basés sur des arbres pourraient être très utiles dans ce problème et **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">kNN</mark>** peut également être ajouté à la liste des modèles surajustés sur les données d’entraînement car ils ont tendance à avoir des scores de validation croisée plus faibles\n",
    "\n",
    "Le **<span style='color:#CDE10F'>temps d’entraînement et d’évaluation</span>** est également assez important dans ce problème :\n",
    "\n",
    "- N’ayant utilisé que (100k/4.5M), le coût même avec 7 caractéristiques est assez élevé pour les modèles plus avancés, (<code>esp.GBM & ANN</code>);\n",
    "- Les modèles plus avancés ont dû être considérablement réduits pour réduire le temps d’entraînement à des niveaux comparables, donc il est souhaitable d’optimiser le processus de sélection des caractéristiques.\n",
    "- **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">XGB</mark>** & **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">CATBoost</mark>**, surprenant étaient assez rapides pour un modèle assez avancé, indiquant qu’il est assez bien optimisé pour être utilisé directement sorti de la boîte.\n",
    "- **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">RandomForest</mark>** étant un modèle similaire à XGB est beaucoup plus lent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#CDE10F'> 4.2 |</span> Évaluation du modèle de caractéristiques mises à jour</b>\n",
    "Nous avons créé de nouvelles caractéristiques avec le <code>feature engineering</code> dans la <code>Section 2.5</code>, générant les caractéristiques mises à jour : dataframe <code>df_feat</code>, essayons à nouveau avec ces nouvelles caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous pouvons voir une amélioration très significative des **<span style='color:#CDE10F'>scores de précision</span>**, par rapport au **<span style='color:#CDE10F'>modèle de base</span>**\n",
    "- **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">LinearDiscriminantAnalysis()</mark>** fonctionne étonnamment bien, non seulement sur l’ensemble d’entraînement mais aussi en validation croisée, c’est aussi l’une des approches les plus rapides, ce qui en fait l’une des approches les plus efficaces pour les grands ensembles de données\n",
    "- Parmi les modèles à score plus élevé **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">LDA</mark>**, ne sont pas étonnamment des modèles plus avancés, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">GBM</mark>**,**<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">XGB</mark>**,**<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">CAT</mark>**,**<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">RF</mark>** également\n",
    "- **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">kNN()</mark>** et **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">GaussianNB()</mark>** les modèles non supervisés ont légèrement moins bien performé, en comparaison avec les modèles d’apprentissage supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#CDE10F\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>OPTIMISATION DE L’EFFICACITÉ DU MODÈLE</b></div>\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>UTILISATION DE LA RÉDUCTION DE DIMENSIONNALITÉ</span></b></p></div>\n",
    "\n",
    "- Un gros problème rencontré lors de la tentative d’atteindre l’objectif dans le problème est le grand nombre de données tick (chaque minute) dans l’ensemble de données, ce qui augmente considérablement le coût d'entrainement et d’évaluation.\n",
    "- Comme les **<span style='color:#CDE10F'>matrices de caractéristiques</span>** dépendent du nombre de caractéristiques et d’instances, une réduction d’une seule caractéristique inutile aurait un impact visible sur le coût de calcul.\n",
    "- Il est donc de la plus haute importance de <b>réduire autant que possible les caractéristiques inutiles</b> au problème, équilibrant entre la précision du modèle et la vitesse d’entraînement/prédiction.\n",
    "\n",
    "<b>Examinons deux approches que l’on pourrait prendre :</b>\n",
    "\n",
    "- <b>(1) Réduction de dimensionnalité via l’évaluation de l’importance des caractéristiques (qui est un processus plus manuel) </b>\n",
    "\n",
    "> Bien que cela soit plus un processus manuel puisque toutes les bibliothèques ne sont pas combinées, essayons de trouver un terrain d’entente entre toutes les approches et de les combiner en une seule fonction d’évaluation de l’<code>importance des caractéristiques</code> pour nous permettre d’identifier, d’évaluer et de supprimer les caractéristiques pour accélérer notre approche.\n",
    "\n",
    "- <b>(2) Réduction de dimensionnalité à l’aide d’algorithmes d’apprentissage non supervisé (processus plus automatisé)</b>\n",
    "\n",
    "> Une collection assez simple de puissants algorithmes de <code>réduction de dimension</code> est à notre disposition dans la bibliothèque <code>sklearn</code>, le seul problème auquel je peux penser est que ; expliquer ce que signifient les caractéristiques résultantes peut être un peu problématique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b><span style='color:#CDE10F'> 5.1 |</span> Réduction de dimensionnalité via l’importance des caractéristiques</b>\n",
    "- Nous pouvons examiner l’<b>Importance des caractéristiques</b> (FI) de certains modèles formés pour comprendre quelles caractéristiques et dans quelle mesure.\n",
    "- Nous pouvons utiliser de telles fonctions minimalistes pour évaluer rapidement l’importance des caractéristiques en nous appuyant sur la <b>variation des approches</b> et les <b>bibliothèques optimisées</b>.\n",
    "- Nous pouvons obtenir une <b>importance relative des caractéristiques</b> en utilisant différentes bibliothèques, la <b>fonction</b> <code>feature_importance</code> comprend :\n",
    "> - **<span style=‘color:#CDE10F’>Corrélation linéaire</span>** avec la fonction abs().\n",
    "> - **<span style=‘color:#CDE10F’>Valeurs SHAP</span>** du modèle de régression Catboost (n_est)\n",
    "> - **<span style=‘color:#CDE10F’>Régresseur RandomForest</span>** (n_est)\n",
    "> - **<span style=‘color:#CDE10F’>Régresseur XGBoost</span>** (n_est)\n",
    "> - **<span style=‘color:#CDE10F’>Régresseur CatBoost</span>** (n_est)\n",
    "> - **<span style=‘color:#CDE10F’>SelectKBest</span>** (k)\n",
    "\n",
    "<div style=\"color:white;display:fill;border-radius:8px;font-size:100%; letter-spacing:1.0px;\"><p style=\"padding: 5px;color:white;text-align:left;\"><b><span style='color:#CDE10F'>AJUSTEMENTS SUPPLÉMENTAIRES</span></b></p></div>\n",
    "\n",
    "- Les scores individuels sont combinés et mis à l’échelle en utilisant <code>MinMaxScaler()</code> & Plot.\n",
    "- L’axe des y représente le score total (un score plus élevé est meilleur, max -> Nombre d’approches).\n",
    "- L’axe des x représente les caractéristiques correspondantes du dataframe d’entrée.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from xgboost import plot_importance,XGBRegressor\n",
    "from catboost import CatBoostClassifier,CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import preprocessing\n",
    "import shap\n",
    "import seaborn as sns\n",
    "\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Plot Correlation to Target Variable only\n",
    "def corrMat(df,target='signal',figsize=(9,0.5),ret_id=False):\n",
    "    \n",
    "    corr_mat = df.corr().round(2)\n",
    "    shape = corr_mat.shape[0]\n",
    "    corr_mat = corr_mat.transpose()\n",
    "    corr = corr_mat.loc[:, df.columns == target].transpose().copy()\n",
    "    \n",
    "    if(ret_id):\n",
    "        return corr\n",
    "\n",
    "''' Feature Importance '''\n",
    "# Various Approaches for quick FI evaluation\n",
    "\n",
    "def fi(ldf,target='signal',n_est=25,num_only=True,\n",
    "       drop_id=None,target_cat=True,drop_na=False):\n",
    "    \n",
    "    # Select only numerical features\n",
    "    if(num_only):\n",
    "        ldf = ldf.select_dtypes(include=['float64','int64'])    \n",
    "    \n",
    "    # Drop all NaN\n",
    "    if(drop_na):\n",
    "        print(f'Before NaN drop: {ldf.shape}')\n",
    "        ldf = ldf.dropna()\n",
    "        print(f'After NaN dropped: {ldf.shape}')\n",
    "    \n",
    "    \n",
    "    ldf = ldf.copy()\n",
    "    # If target is categorical string variable\n",
    "    if(target_cat):\n",
    "        cats = ldf[target].unique()\n",
    "        cats_id = [i for i in range(0,len(cats))]\n",
    "        maps = dict(zip(cats,cats_id))    \n",
    "        ldf[target] = ldf[target].map(maps)\n",
    "    \n",
    "    # If any features are desired to be droped \n",
    "    if(drop_id is not None):\n",
    "        ldf = ldf.drop(drop_id,axis=1)\n",
    "\n",
    "    # Input dataframe containing feature & target variable\n",
    "    y = ldf[target]\n",
    "    X = ldf.drop(target,axis=1)\n",
    "    \n",
    "#   CORRELATION\n",
    "    imp = corrMat(ldf,target,figsize=(15,0.5),ret_id=True)\n",
    "    del imp[target]\n",
    "    s1 = imp.squeeze(axis=0);s1 = abs(s1)\n",
    "    s1.name = 'CORR'\n",
    "    \n",
    "#   SHAP\n",
    "    model = CatBoostRegressor(silent=True,n_estimators=n_est).fit(X,y)\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X)\n",
    "    shap_sum = np.abs(shap_values).mean(axis=0)\n",
    "    s2 = pd.Series(shap_sum,index=X.columns,name='CAT_SHAP').T\n",
    "    \n",
    "#   CATBOOST\n",
    "    model = CatBoostRegressor(silent=True,n_estimators=n_est).fit(X,y)\n",
    "    fit = model.fit(X,y)\n",
    "    rf_fi = pd.DataFrame(model.feature_importances_,index=X.columns,\n",
    "                                         columns=['CAT'])\n",
    "    rf_fi.sort_values('CAT',ascending=False)\n",
    "    s3 = rf_fi.T.squeeze(axis=0)\n",
    "    \n",
    "#   RANDOMFOREST\n",
    "    model = RandomForestRegressor(n_est,random_state=0, n_jobs=-1)\n",
    "    fit = model.fit(X,y)\n",
    "    rf_fi = pd.DataFrame(model.feature_importances_,index=X.columns,\n",
    "                                         columns=['RF'])\n",
    "    rf_fi.sort_values('RF',ascending=False)\n",
    "    s4 = rf_fi.T.squeeze(axis=0)\n",
    "\n",
    "#   XGB \n",
    "    model=XGBRegressor(n_estimators=n_est,learning_rate=0.5,verbosity = 0)\n",
    "    model.fit(X,y)\n",
    "    data = model.feature_importances_\n",
    "    s5 = pd.Series(data,index=X.columns,name='XGB').T\n",
    "\n",
    "#   KBEST\n",
    "    model = SelectKBest(k=5, score_func=f_regression)\n",
    "    fit = model.fit(X,y)\n",
    "    data = fit.scores_\n",
    "    s6 = pd.Series(data,index=X.columns,name='KBEST')\n",
    "\n",
    "    # Combine Scores\n",
    "    df0 = pd.concat([s1,s2,s3,s4,s5,s6],axis=1)\n",
    "    df0.rename(columns={'target':'lin corr'})\n",
    "\n",
    "    # MinMax Scaler\n",
    "    x = df0.values \n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df = pd.DataFrame(x_scaled,index=df0.index,columns=df0.columns)\n",
    "    df = df.rename_axis(f'<b>FI APPROACH</b>', axis=1)\n",
    "    df = df.rename_axis('Feature', axis=0)\n",
    "    \n",
    "    pd.options.plotting.backend = \"plotly\"\n",
    "    fig = df.plot(kind='bar',title='<b>SCALED FEATURE IMPORTANCE</b>',\n",
    "                  color_discrete_sequence=px.colors.qualitative.T10)\n",
    "    fig.update_layout(template='plotly_white',height=400,\n",
    "                     font=dict(family='sans-serif',size=12),\n",
    "                     margin=dict(l=60, r=40, t=50, b=10))\n",
    "    fig.update_traces(width=0.25)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi(df_tr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On peut noter que pour beaucoup de caractéristiques, une petite valeur en magnitude de <code>corrélation</code> (valeur de Pearson) donne également de petites valeurs de score dans d'autres approches. De même, les caractéristiques avec une <code>corrélation</code> élevées ont tendance à avoir des scores élevés dans d'autres méthodes <code>d'importance des caractéristiques</code>, ce qui est assez intéressant. Il existe quelques exceptions, comme <code>%D10</code> et <code>MOM10</code>\n",
    "- Bien que quelques caractéristiques montrent un léger désaccord en ce qui concerne l'importance des caractéristiques, dans l'ensemble, <b>une similarité des scores de caractéristiques peut être observée pour la plupart des approches</b>.\n",
    "- Il est intéressant de noter des dizaines de cas de caractéristiques identiques (par exemple <code>MOM10</code>, <code>MOM30</code>) ; nous pouvons avoir une idée des nouvelles fonctionnalités potentielles que nous pourrions essayer (peut-être que <code>MOM20</code> aurait mieux fonctionné que <code>MOM10</code>)\n",
    "- Nous pouvons observer de nombreuses caractéristiques qui ont une <b>valeur de score relatif très faible</b> pour la plupart des méthodes, et qui ont donc probablement peu ou pas d'impact, même si elles devaient être supprimées.\n",
    "- Supprimer les caractéristiques potentiellement sans impact (soit environ 50 % d'entre elles) rendrait notre approche globale beaucoup plus efficace et nous permettrait de nous concentrer sur des recherches de grille <code>hyperparamètres</code> plus longues et plus approfondies qui, espérons-le, seront plus précises que l'un de nos modèles actuels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tr2_FI = df_tr2.drop(columns=['Open','High','Low','Close','Volume_(Currency)','MA63','EMA10','%K10', 'Timestamp'])\n",
    "df_tr2_FI = df_tr2.drop(columns=['Open','High','Low','Close','Volume_(Currency)','MA21','MA252', 'MA63','EMA10','EMA200','%K10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_FI,split_id=[0.2,None],plot_id=[False,True],cv_yrange=(0.8,1.0),hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <b><span style='color:#CDE10F'> 5.2 |</span> Réduction de dimensionnalité à l’aide d’algorithmes d’apprentissage non supervisé</b>\n",
    "Une approche alternative à la <mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">réduction des caractéristiques</mark> est l’utilisation de méthodes d’<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">apprentissage non supervisé</mark>.\n",
    "\n",
    "- Nous devons sélectionner un algorithme (il est préférable de regarder plusieurs d’entre eux et de voir comment ils se comportent),\n",
    "- Peut-être appliquer une certaine **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">mise à l’échelle</mark>** et simplement <code>fit_transform</code> pour obtenir la <code>matrice de caractéristiques</code> modifiée qui aura la dimension sélectionnée\n",
    "\n",
    "La fonction suivante contient les algorithmes d’ **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">apprentissage non supervisé</mark>** sélectionnables suivants pour réaliser la réduction de dimensionnalité :\n",
    "\n",
    "> - **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">PCA</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Sparse PCA</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Kernel PCA</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Incremental PCA</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Truncated SVD</mark>**\n",
    "> - **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Fast ICA</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Gaussian Random Projection</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Sparse Random Projection</mark>**\n",
    "> - **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">IsoMap</mark>** (Manifold),**<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">MDS</mark>** (Manifold),**<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">TSNE</mark>** (Manifold)\n",
    "> - **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Locally Linear Embedding</mark>**, **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Mini Batch Dictionary Learning</mark>**\n",
    "\n",
    "- Tous ne sont pas réalisables sur Kaggle en raison de la mémoire computationnelle limitée (surtout les approches <b>Manifold</b>), même avec la fonction <code>red_mem</code> activée\n",
    "- Il n’est pas trop rare d’utiliser des approches en plusieurs étapes pour les méthodes **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">manifold</mark>**, par exemple une étape **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">PCA</mark>** avant l’approche **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">manifold</mark>**\n",
    "- Ici, nous utiliserons des approches qui nécessitent moins de ressources pour fonctionner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def dimRed(ldf,feature='signal',split_id=[None,None],n_comp=5,plot_id=True,\n",
    "           model_id='sparserandomprojection',scaler_id=[False,None]):\n",
    "    \n",
    "    # Given a dataframe, split feature/target variable\n",
    "    X = ldf.copy()\n",
    "    y = ldf[feature].copy()\n",
    "    del X[feature]\n",
    "    \n",
    "    n_jobs = -1; rs = 32\n",
    "    \n",
    "    if(model_id is 'pca'):\n",
    "        whiten = False\n",
    "        model = PCA(n_components=n_comp,whiten=whiten,random_state=rs)\n",
    "    if(model_id is 'sparsepca'):\n",
    "        alpha = 1\n",
    "        model = SparsePCA(n_components=n_comp,alpha=alpha,random_state=rs,n_jobs=n_jobs)\n",
    "    elif(model_id is 'kernelpca'):\n",
    "        kernel = 'rbf'; gamma = None\n",
    "        model = KernelPCA(n_components=n_comp,kernel=kernel,gamma=gamma,n_jobs=n_jobs,random_state=rs)\n",
    "    elif(model_id is 'incrementalpca'):\n",
    "        batch_size = None\n",
    "        model = IncrementalPCA(n_components=n_comp,batch_size=batch_size)\n",
    "    elif(model_id is 'truncatedsvd'): \n",
    "        algorithm = 'randomized';n_iter = 5\n",
    "        model = TruncatedSVD(n_components=n_comp,algorithm=algorithm,n_iter=n_iter,random_state=rs)\n",
    "    elif(model_id is 'gaussianrandomprojection'):\n",
    "        eps = 0.5\n",
    "        model = GaussianRandomProjection(n_components=n_comp,eps=eps,random_state=rs)\n",
    "    elif(model_id is 'sparserandomprojection'):\n",
    "        density = 'auto'; eps = 0.5; dense_output = True\n",
    "        model = SparseRandomProjection(n_components=n_comp,density=density, \n",
    "                                       eps=eps, dense_output=dense_output,random_state=rs)\n",
    "    if(model_id is 'isomap'):\n",
    "        n_neigh = 2\n",
    "        model = Isomap(n_neighbors=n_neigh,n_components=n_comp, n_jobs=n_jobs)    \n",
    "    elif(model_id is 'mds'):\n",
    "        n_init = 1; max_iter = 50; metric = False\n",
    "        model = MDS(n_components=n_comp,n_init=n_init,max_iter=max_iter,metric=True,\n",
    "                    n_jobs=n_jobs, random_state=rs)\n",
    "    elif(model_id is 'locallylinearembedding'):\n",
    "        n_neigh = 10; method = 'modified'\n",
    "        model = LocallyLinearEmbedding(n_neighbors=n_neigh,n_components=n_comp, method=method, \\\n",
    "                                    random_state=rs, n_jobs=n_jobs)\n",
    "    elif(model_id is 'tsne'):\n",
    "        learning_rate = 300; perplexity = 30; early_exaggeration = 12; init = 'random'\n",
    "        model = TSNE(n_components=n_comp, learning_rate=learning_rate, \\\n",
    "                    perplexity=perplexity, early_exaggeration=early_exaggeration, \\\n",
    "                    init=init, random_state=rs)\n",
    "    elif(model_id is 'minibatchdictionarylearning'):\n",
    "        alpha = 1; batch_size = 200; n_iter = 25\n",
    "        model = MiniBatchDictionaryLearning(n_components=n_comp,alpha=alpha,\n",
    "                                            batch_size=batch_size,n_iter=n_iter,random_state=rs)\n",
    "    elif(model_id is 'fastica'):\n",
    "        algorithm = 'parallel'; whiten = 'unit-variance'; max_iter = 100\n",
    "        model = FastICA(n_components=n_comp, algorithm=algorithm,whiten=whiten, \n",
    "                          max_iter=max_iter, random_state=rs)\n",
    "    \n",
    "    # Scaling \n",
    "    if(scaler_id[0]):\n",
    "        \n",
    "        opts = [StandardScaler(),RobustScaler(),MinMaxScaler(), Normalizer(norm='l2')]\n",
    "        scaler = opts[scaler_id[1]].fit(X) \n",
    "        X_sca = pd.DataFrame(scaler.fit_transform(X),\n",
    "                                       columns = X.columns,\n",
    "                                       index = X.index) # summarize transformed data \n",
    "    \n",
    "    # Unsupervised Dimension Reduction \n",
    "    if(scaler_id[0]):\n",
    "        X_red = model.fit_transform(X_sca)\n",
    "    else:\n",
    "        X_red = model.fit_transform(X)\n",
    "    X_red = pd.DataFrame(data=X_red, index=X.index)\n",
    "    if(plot_id):\n",
    "        scatterPlot(X_red, y,model_id)\n",
    "    X_red[feature] = y\n",
    "    \n",
    "    return X_red # return new feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nous utilisons la réduction de dimensionnalité sur <code>df_tr2</code>, avant d'utiliser la fonction <code>modelEval</code> comme avant, en notant la précision et les temps d'exécution\n",
    "- Pour la réduction de dimensionnalité, nous utiliserons ici **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">Fast ICA</mark>** avec différents **<mark style=\"background-color:#CDE10F;color:white;border-radius:5px;opacity:0.9\">méthodes de mise à l'échelle des données</mark>**, vous pouvez essayer différentes combinaisons, le but étant pour obtenir la plus grande précision possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard ICA (no scaling)\n",
    "df_tr2_ICA = dimRed(df_tr2_FI,\n",
    "                    split_id=[0.2,None],\n",
    "                    model_id='fastica',\n",
    "                    n_comp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_ICA,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''StandardScaler ICA'''\n",
    "df_tr2_ICA_sca0 = dimRed(df_tr2_FI,\n",
    "                         split_id=[0.2,None],\n",
    "                         model_id='fastica',\n",
    "                         n_comp=5,\n",
    "                         scaler_id=[True,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_ICA_sca0,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''RobustScaler ICA'''\n",
    "df_tr2_ICA_sca1 = dimRed(df_tr2_FI,\n",
    "                         split_id=[0.2,None],\n",
    "                         model_id='fastica',\n",
    "                         n_comp=5,\n",
    "                         scaler_id=[True,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_ICA_sca1,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''MinMaxScaler ICA'''\n",
    "df_tr2_ICA_sca2 = dimRed(df_tr2_FI,\n",
    "                         split_id=[0.2,None],\n",
    "                         model_id='fastica',\n",
    "                         n_comp=5,\n",
    "                         scaler_id=[True,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_ICA_sca2,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Normaliser ICA'''\n",
    "df_tr2_ICA_sca3 = dimRed(df_tr2_FI,\n",
    "                         split_id=[0.2,None],\n",
    "                         model_id='fastica',\n",
    "                         n_comp=5,\n",
    "                         scaler_id=[True,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelEval(df_tr2_ICA_sca3,\n",
    "          split_id=[0.2,None],\n",
    "          plot_id=[False,True],\n",
    "          cv_yrange=(0.8,1.0),\n",
    "          hm_vvals=[0.8,1.0,0.9])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1346,
     "sourceId": 2109006,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
